
<html xmlns=http://www.w3.org/1999/xhtml>
<head>
  <title>Jonne Sälevä</title>
  <style type=text/css>code{white-space: pre;}</style>
  <link rel=stylesheet href=../static/css/style.css type=text/css />
  <script src=https://polyfill.io/v3/polyfill.min.js?features=es6></script>
  <script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
</head>

<body>
<div id="topheader"> <h1 id="research-interests">research interests</h1> </div> <thead> <tr> <td> <a href="/">Home</a> </td> <td> <a href="/research">Research</a> </td> <td> <a href="/portfolio">Portfolio</a> </td> <td> <a href="/resume">Resume</a> </td> </tr> </thead> <hr /> <div id="container"> <p>My main interest lie in the field of human language technology, and generally applying machine learning to language. Some examples include:</p> <ul> <li><strong>low-resource + morphologically rich languages:</strong> how can we have better representations inside, e.g. a neural machine translation model, such that morphology is captured in a systematic way?</li> <li><strong>unsupervised representation learning:</strong> more generally, how can we engineer representations from unlabeled data? can we move beyond point estimates for things like word embeddings?</li> <li><strong>sequence transduction problems</strong>: machine translation, transliteration, grapheme-to-phoneme conversion, speech recognition, …</li> <li><strong>bayesian methods and model comparison</strong>: how can we add interpretable uncertainty estimates to our models? how do we <em>really</em> know that model a performed better than model b on some task/dataset?</li> </ul> </div> <hr /> <tfoot> <tr> <td> © Jonne Sälevä, 2020 </td> </tr> </tfoot>

</body>
</html>

