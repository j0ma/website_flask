<div id='topheader'>

# research interests

</div>

<thead>

<tr>

  <td>[Home](/)</td>

  <td>[Research](/research)</td>

  <td>[Portfolio](/portfolio)</td>

  <td>[Resume](/resume)</td>

  <td>[Blog](http://blog.jonnesaleva.com)</td>

</tr>

</thead>

---

<div id='container'>

My main interests are machine learning and language. But since that kind of covers almost everything, a low-dimensional projection of my interests could be:

- **representation learning:** how can we engineer representations that, on the one hand, contain all of our prior information, yet also aid in generatlization? can we be sure of our representations? can we be bayesian and quantify that uncertainty using probabilities?
- **low-resource speech recognition:** what to do when there are (almost) no resources available for a language?
- **"meta" machine learning:** bayesian optimization in training, hyperparameter selection. also learning-to-learn, like composing primitive operations to learn representations of categories.

Beyond the above, I'm generally curious about bayesian machine learning and the many fields utilizing probabilistic models to solve their problems.

I also love well-made visualizations, and strongly believe that we ought to visualize not only raw data, but model inferences and uncertainty as well. I admit I've been influenced by [Andrew Gelman](https://www.andrewgelman.com) and the recent goings-on of the [Stan project](https://www.mc-stan.org).

Finally, as a product of [open online educational resources](http://www.khanacademy.org) myself, I believe that all of the above can and should be applied to educating people and openly sharing knowledge online.

</div>

---

<tfoot>

<tr>

  <td>© Jonne Sälevä, 2017 || inspired by [cfdenton](https://cfdenton.github.io)</td>

</tr>

</tfoot>